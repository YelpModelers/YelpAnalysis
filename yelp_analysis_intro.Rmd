---
title: "Predicting Restaurant Popularity in Metropolitan Areas from Yelp Statistics"
output: pdf_document
fig_caption: yes
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Project Overview

To use data from Yelp to discover what factors result in a “popular” restaurant and whether these factors can be used to predict the popularity of previously unseen restaurants. Popularity in this instance is defined as the rate of both number of check-ins and number of new reviews over a given time period (weekly/monthly). This will give an approximation as to how actively customers are visiting a given restaurant. Factors such as the physical facilities, operating characteristics and customer behaviours will be included as predictors.

In order to keep data sizes manageable we will be focusing on restaurants and food business in the Las Vegas area.

### Data Sources

Yelp review data - https://www.yelp.com/dataset/download

A useful metadata dictionary table can be found in the appendix of this report, whilst variables have been named appropriately for their data, please see the metadata dictionary for further clarifications of variable intent (Appendix section 1.1).


# Hypotheses

What attributes of restaurants and reviews contribute to the ‘popularity’ of restaurants?

* Restaurants with a higher than average proportion of tagged reviews - aka reviews with "cool", "funny" or "useful" reviews will be more popular due to the increased engagement these reviews might have.
* Having a higher proportion of reviews by ‘influencers’ (defined by criteria such as number of fans, elite status) will increase the popularity of a restaurant. 
* Restaurants with a greater number of attributes (parking, wifi, etc.) will be more popular.

Further possible questions:

* Can future popularity be predicted for new unseen restaurants previously unseen restaurants?
* Can trends in restaurant type over time (American food, Bar food, Tapas etc.) be studied from the data to understand how tastes have changed?


# Data Preprocessing

**NOTE:** Much of the data processing was performed in Python for performance reasons as many of the initial JSON datasets were >5GB in size. This created issues with storing data in RAM and hence the approach used was to yield chunks of data at a time, storing only subsets. The python data processing code can be found in the Appendix (section 1.2) for further details and to ensure proper recording and reproducibility of code from this report.

### Flow

The data came in multiple JSON files each explaining it's own subset of the overall Yelp dataset. For our purposes the most relevant tables are businessess (a full list of all businesses with unique *business_id*), reviews (a full list of all reviews for those business with a link to the the user who wrote it: unique *business_id*, unique *review_id*, unique *user_id*) and users (all the user information for those reviews: unique *user_id*).

In order to begin modelling we first had to combine all these tables into a clean dataset. To do this though as the tables were too large to keep in memory we decided to cut down the scope from all USA food businesses to just Las Vegas, which was the largest city for number of food businesses, and so this reduced the initial business list down to just 30,000 unique businesses. From here the data processing was as follows:

1. Run through all Reviews in chunks and keep only those corresponding to the 30,000 unique businesses. (Later on in the business processing this would be reduced again to just food businesses).
2. Resolve a list of unique review_ids from those remaining reviews
3. Run through all Users in chunks and keep only those corresponding to the remaining reviews.
4. Clean and aggregate the business categorical and attribute information (see below)
5. Clean and aggregate the review data to business level - calculate sum and mean statistics for counts such as "cool" and "funny" reviews
6. Clean the user table and compute relevant statistics such as 'outlier' reviewers and 'elite' reviewers
7. Left join the user data onto the review data (keep all rows from review and join in user information)
8. Left join the user/review table onto the business table

These steps can be seen in the flow diagram below (figure 1).

```{r, echo=FALSE,fig.cap="\\label{fig:figs}Top Food Related Business Categories"}
library(png)
library(grid)
img <- readPNG("data_processing_flow.png")
 grid.raster(img)
```

## Business Data Processing

After filtering to the city of Las Vegas, and only businesses that were open, we were left with 23,793 businesses.

Looking at the categories broadly, we get an initial breakdown by count:

| Category         | Frequency |
| ---------------- | ----- |
| Restaurants      | 4,221 |
| Shopping         | 4,144 |
| Home Services    | 3,508 |
| Health & Medical | 2,927 |
Table: Initial category frequency counts

The category variable is a comma separated list of categories the business fits into, of varying specificity. Including Restaurant, Food, and also more specifics like cuisine and specific dishes (eg Chimney Cakes, Churros).

Yelp provides a list of possible categories on their site. We went through this and manually extracted 416 "food and bar related" categories. We then processed through the category variables, filtering food related businesses and extracting the first more descriptive category the business fell into (ie cuisine) so that the category variable is a single label. If no further descriptive categories were provided, "restaurant" or "bar" was returned.

We are then left with 5,573 food related businesses in Las Vegas, with 171 unique top categories.

```{r fig.width=10, echo=FALSE,fig.cap="\\label{fig:figs}Top Food Related Business Categories (seaborn)"}
library(png)
library(grid)
img <- readPNG("TopCategories.png")
 grid.raster(img)
```


We also had to clean the JSON attribute dictionary and determine the most common attributes available between all businesses.

```{r fig.width=10, echo=FALSE,fig.cap="\\label{fig:figs}Top Business Attributes (seaborn)"}
img <- readPNG("TopAttributes.png")
 grid.raster(img)
```


After filtering out the non-relevant attributes, we also needed to one-hot encode the attribtues that weren't true/false like abiance (which includes: "divey","classy","hipster" etc.). We were unable to leave these as one column factor. After addressing NaNs vs. blank objects, we were left with the final predictors for each business (as seen in the final table metadata appendix section).


## User Data Processing

As the user data is already at a single row of data per user there was no aggregation required. However to get the most out of the users table we need relevant statistics that will eventually be aggregated up to business level for the final dataset. Hence much of the original user information would be of little use at this higher aggregate level.

To overcome this we decided to focus on a number of key user statistics that would be helpful at business level:

* Users with "outlier" number of friends/fans
* Users with elite status
* Users friend network
* Users activity


#### NA issues in User Data

One of the biggest issues with processing the user data is that the data is not a perfect subset of the reviews data. Our initial hypothesis on the data is that Yelp had provided a subset of businesses throughout the US and their relevant reviews and user data. However this was incorrect. Whilst the review data did match up well to the businesses, the users did not match up anywhere near so neatly to the reviews table.

In fact on for most businesses reviews we only have around 65-70% of the user data. The remaining 30-35% of user information is entirely missing from the provided data. In essence this means we are missing data on a third of the users who wrote the reviews on our businesses of interest. 

Aggregating the data from individual review to business level overcomes a lot of the processing issues (in terms of NAs) although we do need to be aware that our user information is not built upon complete data. An example:

| Business_id | Review_id         | User_id | Number_of_friends |
| --------- | ---------------- | ----- | -------- |
| Restaurant_1 | Review 1      | UserA | 10 |
| Restaurant_1 | Review 2         | UserB | 50 |
| Restaurant_1 | Review 3    | NA | NA |
| Restaurant_1 | Review 4 | UserC | 90 |

So when this data is aggregated up to business level there aren't any overall NAs - we have enough data to compute the average statistics we need for the analysis:

| Business_id |  Total_Number_of_friends |
| --------- | ------- |
| Restaurant_1 | 150 |

However this means that we are assuming that our data on users is missing totally at random and that on average our missing data should not skew or effect the statistics we compute for each business. In this case the missing user could have had 10,000 friends and therefore the reviews would be reaching a much larger audience than we would see in the data. There is however no way to impute this data and so this is an assumption we have to live with and will be noted alongside any results.

# EDA

## Response Variable   
We wish to learn what attributes of a restaurant contribute to the popularity of a restaurant. Here we define 'popularity' of a restaurant to encompass: 1) frequency of visits to the restaurant as proxied by the number of check-in's and 2) number of Yelp reviews the restaurant received. Based on this definition, the 'popularity' measure of a restaurant was constructed as follows:  

$\frac{\text{Number of check-in's} + \text{Number of Yelp reviews}}{\text{Number of months open}}$

The total sum of check-in's and reviews for a business is divided by how long the business has been open to make the popularity measure comparable across businesses that have been open for different durations. The Yelp dataset does not provide information about how long a business has been open; the number of months a business has been open was approximated by computing the difference in the latest and oldest dates of reviews or check-in's. 
```{r, echo=FALSE}
vy <- read.csv("data/vegas_yelp_dataset.csv")
```

```{r, echo=FALSE}
vy$popularity <- (vy$review_count_business + vy$checkin_count) / vy$months_open

# explore distribution of 'popularity' response variable
popularity = vy$popularity
knitr::kable(summary(popularity))
hist(popularity, main="Distribution of Popularity",col="grey")

# look at the spread of popularity for businesses with 

# count number of restaurants with 'outlier' popularity values (based on 3rd Quartile + 1.5 * IQR rule)
outlier_threshold = quantile(popularity)[4] + (1.5 * IQR(popularity))
#print("Threshold for outlier popularity value")
#print(outlier_threshold)
#print("Number of restaurants considered to have outlier values for popularity")
#nrow(vy[vy$popularity > outlier_threshold,])

# response variable is highly right-skewed - perform log transformation
hist(log(popularity), main="Distribution of Log-transformed Popularity", col="grey")

# create log-transformed popularity variable
vy$popularity_log <- log(vy$popularity)
qqnorm(log(vy$popularity), main="Q-Q plot of log-transformed Popularity")
qqline(log(vy$popularity))
```

The median popularity of restaurants is approximately 4.41 and 75% of restaurants have a popularity measure below 14.94. There are 630 restaurants considered to have outlier values for popularity measure (outliers defined as values above 3rd Quantile + 1.5*IQR or `r outlier_threshold`). The response value is highly right-skewed; the normality assumption on whcih the linear model relies upon will most likely be violated. The response variable could be log-transformed, yielding a symmetric distribution. 


## Exploring Predictors   

Not all features included in the dataset may be suitable for predicting popularity of restaurants: for example, certain features may have too many missing observations or several features may be highly correlated with one another. Here we explore 1) how certain features are distributed across businesses 2) missingness and potential multicollinearity issues in predictors 2) relationship between popularity and the predictors 

```{r, echo=FALSE}
vy_summary <- summary(vy)
knitr::kable(vy_summary[,1:4])
knitr::kable(vy_summary[,5:8])
knitr::kable(vy_summary[,9:12])
knitr::kable(vy_summary[,13:16])
knitr::kable(vy_summary[,17:20])
knitr::kable(vy_summary[,21:24])
knitr::kable(vy_summary[,25:28])
knitr::kable(vy_summary[,29:32])
knitr::kable(vy_summary[,33:36])
knitr::kable(vy_summary[,37:40])
knitr::kable(vy_summary[,41:44])
knitr::kable(vy_summary[,45:48])
knitr::kable(vy_summary[,49:52])
knitr::kable(vy_summary[,53:56])
knitr::kable(vy_summary[,57:60])
knitr::kable(vy_summary[,61:64])
knitr::kable(vy_summary[,65:68])
knitr::kable(vy_summary[,69:72])
knitr::kable(vy_summary[,73:77])
```

## Distribution of Predictors across Businesses
```{r, echo=FALSE}
# check data types of variables
#sapply(vy, class)

# convert RestaurantsPriceRange2 into a factor variable
vy$RestaurantsPriceRange2 <- factor(vy$RestaurantsPriceRange2)
```

TopCategory variable indicates the 'main' cuisine or food cateogry a business serves. We explore how many different categories exist and the number of businesses associated for each of the categories

```{r, echo=FALSE}
n_topcategories = length(unique(vy$TopCategory))
category_table = table(vy$TopCategory)
category_df = as.data.frame(category_table)
colnames(category_df)[colnames(category_df)=="Var1"] <- "Category"
colnames(category_df)[colnames(category_df)=="Freq"] <- "Frequency"

category_df <- category_df[order(category_df$Frequency, decreasing = TRUE),][1:15,]
knitr::kable(category_df)
```

There are `r n_topcategories` different food categories. We may wish to merge categories for which there are only a few businesses into 'Other' category. 


## Exploring Relationship Predictors and Response

Here we explore the relationship bewteen quantitaive predictors and the response. We are interested in learning whether there appears to be a relationship between the predictors and the response and if so whether or not the relationship is linear. 
**Note: in all plots below, popularity variable has been log-transformed. The predictors are also heavily right-skewed and we may consider log-transforming the predictors as well. For some predictors, the minimum value observed is zero; a small constant should be added to all values of the observation when performing log-transformation**


```{r fig4, fig.height = 3.5, fig.width = 14, echo=FALSE}
par(mfrow=c(1,3))
hist(vy$cool_review_pm, main="", xlab="Number of 'cool' votes reviews of a business received per month", cex.lab=2)
hist(vy$funny_review_pm, main="", xlab="Number of 'funny' votes reviews of a business received per month", cex.lab=2)
hist(vy$useful_review_pm, main="", xlab="Number of 'useful' votes reviews of a business received per month", cex.lab=2)
summary(vy$cool_review_pm)
summary(vy$funny_review_pm)
summary(vy$useful_review_pm)

plot(popularity_log~cool_review_pm, data=vy, xlab="Number of 'cool' votes reviews of a business received per month", ylab="log (popularity)", cex.lab=2)
plot(popularity_log~funny_review_pm, data=vy, xlab="Number of 'funny' votes reviews of a business received per month", ylab="log (popularity)", cex.lab=2)
plot(popularity_log~useful_review_pm, data=vy, xlab="Number of 'useful' votes reviews of a business received per month", ylab="log (popularity)", cex.lab=2)

plot(popularity_log~log(cool_review_pm), data=vy, xlab="log (Number of 'cool' votes reviews of a business received per month)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)
plot(popularity_log~log(funny_review_pm), data=vy, xlab="log (Number of 'funny' votes reviews of a business received per month)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)
plot(popularity_log~log(useful_review_pm), data=vy, xlab="log (Number of 'useful' votes reviews of a business received per month)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)
```

'cool', 'funny', and 'useful' votes are highly right-skewed; we may consider log-transforming these predictors as well. There appears to be a strong positive relationship between popularity and the number of 'cool', 'funny', and 'useful' votes reviews of a business receive per month. 



```{r fig11, fig.height = 3.5, fig.width = 14, echo=FALSE}
par(mfrow=c(1,2))
hist(vy$elite_users_sum, main="", xlab="Number of elite-status reviewers for a business", cex.lab=2)
hist(vy$review_users_mean, main="", xlab="Mean number of reviews written by reviewers of a business", cex.lab=2)
#summary(vy$elite_users_sum)
#summary(vy$review_users_mean)

plot(popularity_log~elite_users_sum, data=vy, xlab="Number of elite-status reviewers for a business", ylab="log (popularity)", cex.lab=2)
plot(popularity_log~review_users_mean, data=vy, xlab="Mean number of reviews written by reviewers of a business", ylab="log (popularity)", cex.lab=2)

plot(popularity_log~log(elite_users_sum), data=vy, xlab="log (Number of elite-status reviewers for a business)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)
plot(popularity_log~log(review_users_mean), data=vy, xlab="log (Mean number of reviews written by reviewers of a business)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)

```

The number of elite-status reviewers and mean number of reviews written by reviewers are right-skewed; again, we may consider log-transforming these predictors.

How 'active' reviewers of a business are, as proxied by the mean number of reviews written by reviewers of a business, may not be associated with the popularity of a business. There appears to be a positive association between the number of elite-status reviewers for a business and a business' popularity. This positive relationship may simply be due to the fact that businesses with a greater number of reviews (which was used to derive the popularity of a business) are also more likely to have a greater number elite-status reviewers. To correct for this, we should divide the number of elite-status reviewers for a business by the total number of reviews for a business. 


```{r fig12, fig.height = 3.5, fig.width = 5, echo=FALSE}
plot(popularity_log~log(elite_users_sum/review_count_business), data=vy, xlab="log (Number of elite-status reviewers for a business / Number of reviews for a business)", ylab="log (popularity)")

```

When we adjust the number of elite-status reviewers for a business by the number of reviews it received, we no longer see a strong positive relationship between the prevalence of elite-status reviewers and popularity of a business.  



```{r fig13, fig.height = 3.5, fig.width = 14, echo=FALSE}
par(mfrow=c(1,2))
hist(vy$fans_users_mean, main="", xlab="Mean number of fans reviewers of a business have", cex.lab=2)
hist(vy$friend_number_mean, main="", xlab="Mean number of friends reviewers of a business have", cex.lab=2)
#summary(vy$fans_users_mean)
#summary(vy$friend_number_mean)

plot(popularity_log~fans_users_mean, data=vy, xlab="Mean number of fans reviewers of a business have", ylab="log (popularity)", cex.lab=2)
plot(popularity_log~friend_number_mean, data=vy, xlab="Mean number of friends reviewers of a business have", ylab="log (popularity)", cex.lab=2)

plot(popularity_log~log(fans_users_mean), data=vy, xlab="log (Mean number of fans reviewers of a business have)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)
plot(popularity_log~log(friend_number_mean), data=vy, xlab="log (Mean number of friends reviewers of a business have)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)

```

There does not appear to be a strong association between the mean number of fans/friends reviewers of a business have and the popularity of a business. 

```{r fig14, fig.height = 3.5, fig.width = 14, echo=FALSE}
par(mfrow=c(1,2))
hist(vy$fan_outlier_count, main="", xlab="Number of reviewers with outlier fan counts for a business", cex.lab=2)
hist(vy$friend_outlier_count, main="", xlab="Number of reviewers with outlier friend counts for a business", cex.lab=2)
#summary(vy$fan_outlier_count)
#summary(vy$friend_outlier_count)

plot(popularity_log~fan_outlier_count, data=vy, xlab="Number of reviewers with outlier fan counts for a business", ylab="log (popularity)", cex.lab=2)
plot(popularity_log~friend_outlier_count, data=vy, xlab="Number of reviewers with outlier friend counts for a business", ylab="log (popularity)", cex.lab=2)

plot(popularity_log~log(fan_outlier_count), data=vy, xlab="log (Number of reviewers with outlier fan counts for a business)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)
plot(popularity_log~log(friend_outlier_count), data=vy, xlab="log (Number of reviewers with outlier friend counts for a business)", main="Predictor log-transformed", ylab="log (popularity)", cex.lab=2, cex.main=2)

```
There appears to be a positive correlation between the number of reviewers with outlier fan/friend counts for a business and the popularity of a business: businesses that have greater of number reviewers with a lot of fans or friends tend to be more popular. Again, the positive correlation between the response and these predictors may simply be due to the fact that businesses that have more reviews (thus greater popularity) are more likely to have greater number of reviewers with outlier fan/friend counts. As before, we adjust the number of reviewers with outlier fan/friend counts by dividing by the total number of reviews for the business. 

```{r fig15, fig.height = 3.5, fig.width = 14, echo=FALSE}
par(mfrow=c(1,2))
plot(popularity_log~log(fan_outlier_count/review_count_business), data=vy, xlab="log (Number of reviewers with outlier fan counts for a business / Number of reviews)", ylab="log (popularity)", cex.lab=2, cex.main=2)

plot(popularity_log~log(friend_outlier_count/review_count_business), data=vy, xlab="log (Number of reviewers with outlier friend counts for a business / Number of reviews)", ylab="log (popularity)", cex.lab=2, cex.main=2)

```

Now we no longer see as strong of a positive correlation between the number of reviewers with outlier fan/friends and popualrity. 


### Missing Values    
There are missing values for multiple features
- 26 businesses do not have any information about their reviewers
- Missing values are prevalent for categorical variables (e.g. BikeParking, HasTV, RestaurantsGoodForGroups, etc.)

```{r, echo=FALSE}
# replace blanks with NA
for (i in 2:ncol(vy)){
  vy[,i][vy[,i] == ""] <- NA
}
```

```{r, echo=FALSE}
# get number of businesses with complete observations 
n_complete <- nrow(vy[complete.cases(vy),])
```
If we exclude businesses missing values for any of the features, we are left with `r n_complete` businesses in the dataset. Inputing missing values in our categorical variables does not seem appropriate (for example, if a business has a NA for the 'GoodforKids' attribute, it does not seem reasonable to impute True or False). Given that our dataset is large enough even after dropping businesses with missing values for any of the attributes, we may leave the missing values as they are.   


## Correlations between Predictors

### Reviewer related Variables
The dataset contains information about the reviewers of a business. For example, for each business we computed the mean number of reviews the business' reviewers have written on Yelp overall*, the mean number of fans the business' reviewers have, the mean number of 'cool' votes the business' reviewers gave on Yelp overall, etc. These variables are intended to capture how active or 'influential' reviewers of a business might be. We could imagine that the more active and influential the reviewers of a business are, the more popular the business. These reviewer related variables, however, may be highly correlated with each other.   

*Each reviewer has a total number of reviews that he/she has written on Yelp, not just for that single business. We took these review counts and averaged across reviewers of a business.   

```{r fig16, fig.height = 10, fig.width = 10, echo=FALSE}
# scatter plots of reviewer related variables 
pairs(~cool_users_mean+funny_users_mean+useful_users_mean+review_users_mean+fans_users_mean+friend_number_mean,
      data=vy, main="Scatterplots of reviewer related variables")

```
There are very strong positive correlations between the reviewer related variables. Take for example, the greater the mean number of 'useful' votes a business' reviewers gave on Yelp overall, the greater the mean number of 'cool' and 'funny' votes they gave on Yelp overall. The mean number of friends and the mean number of fans a business' reviewers have are positively correlated with each other. The mean number of reviews by a business' reviewers on Yelp overall is also highly correlated with all other reviwer related variables. Given the strong positive correlation between the various reviewer related variables, we should consider using only a subset of them in our models. 


# Assumptions

1. Missing users are missing completely at random from the dataset and so therefore will not skew our calculations for business user statistics.
2. 


# Next Steps
Performing this EDA has illuminated some issues that we will resolve in our next iteration for modeling.

- Reduce number of categories of food businesses from 171 -- putting non top ones into an “other” bucket
- Variables that are too correlated with review count will be converted to proportions
- Fan outlier count
- Friend outlier count
- Elite users sum
- In model, we will drop all of the sum aggregations in favor of means since we realized this is essentially duplicate information
- N/As: from users table and in business attributes, we are unable to robustly impute things like 0 or “false” so we will keep these missing values for now. Though these observations will be dropped from our model, we will still have ½ of the dataset remaining which is still a very strong samplesize.


# Appendix

### 1.1 - Metadata

|| id | dataset | description|
|- | ---- |-|---------|
|0| address | business | string |
| 1 | business_id | business | string, 22 character unique string business id |
|2| city | business | city ( Las Vegas)|
|3| latitude | business | latitude|
|4| longitude | business | longitude|
|5| name | business | business name|
|6| postal_code | business | US postal code|
|7 | review_count_business | business | number of reviews for the business|
|8 | stars_business | business | star rating for the business|
|9 | state | business | state|
|10 | TopCategory | business | top category from within the list of possible business types|
|11 | BikeParking | business | has bike parking y/n|
|12 | RestaurantsPriceRange2 | business | price range|
|13 | HasTV | business | restaurant has TV|
|14 | RestaurantsGoodForGroups | business | restaurant is good for groups|
|15 | OutdoorSeating | business | outdoor seating|
|16 | RestaurantsReservations | business | restaurants has reservations|
|17 | GoodForKids | business | good for kids|
|18 | Alcohol | business | alcohol served|
|19 | NoiseLevel | business | noiseLevel|
|20 | BusinessAcceptsCreditCards | business | accepts credit cards|
|21 | WiFi | business | WiFi|
|22 | RestaurantsAttire | business | restaurant attire|
|23 | Caters | business | caters|
|24 | RestaurantsTakeOut | business | takeOut|
|25 | RestaurantsDelivery | business | delivery|
|26 | garage | business | garage|
|27 | lot | business | lot|
|28 | street | business | street|
|29 | valet | business | valet|
|30 | validated | business | validated|
|31 | casual | business | casual|
|32 | classy | business | classy|
|33 | divey | business | divey|
|34 | hipster | business | hipster|
|35 | intimate | business | intimate|
|36 | romantic | business | romantic|
|37 | touristy | business | touristy|
|38 | trendy | business | trendy|
|39 | upscale | business | upscale|
|40 | breakfast | business | breakfast|
|41 | brunch | business | brunch|
|42 | dessert | business | dessert|
|43 | dinner | business | dinner|
|44 | latenight | business | latenight|
|45 | lunch | business | lunch|
|46 | checkin_count | reviews | checkin_count|
|47 | months_open | reviews | number of months restaurant has been open|
|48 | review_count | reviews | number of reviews for the business from reviews (duplicate?)|
|49 | cool_review_count | reviews | number of reviews tagged as cool|
|50 | funny_review_count | reviews | number of reviews tagged as funny|
|51 | useful_review_count | reviews | number of reviews tagged as useful|
|52 | popularity | reviews | response variable - overall measure of popularity by combining |
|53 | cool_review_pm | reviews | number of cool reviews per month|
|54 | funny_review_pm | reviews | number of funny reviews per month|
|55 | useful_review_pm | reviews | number of useful reviews per month|
|56 | cool_review_mean | reviews | mean number of cool reviews|
|57 | funny_review_mean | reviews | mean number of funny reviews|
|58 | stars_review_mean | reviews | mean number of review stars|
|59 | useful_review_mean | reviews | mean number of useful reviews|
|60 | stars_users_mean | users | mean number of average stars per user who reviewed|
|61 | cool_users_mean | users | mean number of cool votes by users who reviewed|
|62 | elite_users_sum | users | "number of users who have ever been elite |
|63 | fans_users_sum | users | sum total number of fans of all those who reviewed|
|64 | fans_users_mean | users | mean number of fans of all those who reviewed|
|65 | funny_users_mean | users | mean number of funny votes by users who reviewed|
|66 | review_users_sum | users | total number of reviews written by users who reviewed|
|67 | review_users_mean | users | mean number of reviews written by users who reviewed|
|68 | useful_users_sum | users | total number of useful votes by users who reviewed|
|69 | useful_users_mean | users | mean number of useful votes by users who reviewed|
|70 | friend_number_count | users | sum total number of friends of all those who reviewed|
|71 | friend_number_mean | users | mean number of friends of all those who reviewed|
|72 | reviews_users_pm_mean | users | mean number of reviews written per month by those who reviewed|
|73 | fan_outlier_count | users | number of users who reviewed who are considered an outlier in terms of their number of fans|
|74 | friend_outlier_count | users | number of users who reviewed who are considered an outlier in terms of their number of friends|
Table: Metadata for our final cleaned dataframe

### 1.2 - Data Processing Code

#### 1.2.1 - Read and Chunk Data

Python code to read in the raw data and deal with the large JSON files.

```{r, eval=FALSE}
import pandas as pd
import numpy as np

# Constants
city_name = 'Las Vegas'
output_review_name = 'data/LV_reviews.csv'
output_users_name = 'data/LV_users.csv'

# Get business IDS
business = pd.read_json('data/business.json', lines=True)
subset_business_ids = set(business[business['city']==city_name]['business_id'])

# Get chunks from large datasets
user_chunks = pd.read_json('data/user.json', lines=True, chunksize=100000)
review_chunks = pd.read_json('data/review.json', lines=True, chunksize=100000)

# Set up empty df columns
for chunk in user_chunks:
    columns_users = chunk.columns
    break

for chunk in review_chunks:
    columns_reviews = chunk.columns
    break

# Get reviews from the business subet
reviews_df = pd.DataFrame(columns=columns_reviews)
for chunk in review_chunks:
    subset = chunk[chunk['business_id'].isin(subset_business_ids)]
    reviews_df = reviews_df.append(subset, ignore_index = True)

# Subset Users by Reviews
subset_user_ids = set(reviews_df['user_id'])

# Get users from reviews
users_df = pd.DataFrame(columns=columns_users)
for chunk in user_chunks:
    subset = chunk[chunk['user_id'].isin(subset_user_ids)]
    users_df = users_df.append(subset, ignore_index = True)

# Write files
users_df.to_csv(output_users_name)
reviews_df.to_csv(output_review_name)
```


#### 1.2.2 - Clean User Data

Python code to take the user data, calculate statistics and 

```{r, eval=FALSE}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import datetime

# Constants
city_name = 'Las Vegas'

# ------------------------- #
#    READ AND CLEAN DATA
# ------------------------- #
# Read data
users = pd.read_csv('data/LV_users.csv', low_memory=False)
users = users.drop('Unnamed: 0', axis=1)

reviews = pd.read_csv('data/LV_reviews.csv', low_memory=False)
reviews = reviews.drop('Unnamed: 0', axis=1)
# Clean NAs (only 1 for vegas)
reviews = reviews.dropna()

business = pd.read_csv('data/business.csv', low_memory=False)
business = business.drop('Unnamed: 0', axis=1)

business = business[business['city'] == 'Las Vegas']


# Clean Reviews
# Get the last review to represent the end of the dataset
latest_review = sorted(reviews['date'], reverse=True)[0]

# Convert dates
latest_review = datetime.datetime.strptime(latest_review, '%Y-%m-%d %H:%M:%S')
users['yelping_since_date'] = [datetime.datetime.strptime(x[-1], '%Y-%m-%d %H:%M:%S') for 
                               x in users.itertuples()]

# average days per month
av_day_per_month = 30.44

# ------------------------- #
#   CALCULATE USER STATS
# ------------------------- #
users['count_friends'] = [len(row[-8].split(',')) for row in users.itertuples()]
users['months_of_activity'] = latest_review - users['yelping_since_date']
users['months_of_activity'] = [x.days for x in users['months_of_activity']]
users['months_of_activity'] = round(users['months_of_activity']/av_day_per_month)
users['reviews_per_month'] = users['review_count'] / users['months_of_activity']
users['elite_binary'] = np.where(pd.isna(users['elite']), 0, 1)

# Friends
Q1, Q3 = np.percentile(users['count_friends'], [25 ,75])
IQR = Q3 - Q1
influencer_friend_threshold = Q3 + (IQR*1.5)

# Fans
Q1, Q3 = np.percentile(users['fans'], [25 ,75])
IQR = Q3 - Q1
influencer_fan_threshold = Q3 + (IQR*1.5)

users['fan_outlier'] = np.where(users['fans']>influencer_fan_threshold, 1, 0)
users['friend_outlier'] = np.where(users['count_friends']>influencer_friend_threshold, 1, 0)

# ------------------------- #
#          JOINING
# ------------------------- #
# Ensure all ids are string
reviews.loc[:,'user_id'] = reviews['user_id'].astype(str)
reviews.loc[:,'business_id'] = reviews['business_id'].astype(str)
users.loc[:,'user_id'] = users['user_id'].astype(str)
business.loc[:,'business_id'] = business['business_id'].astype(str)

# Ensure there are no leading or trailing spaces
reviews['user_id'] = [string.strip(" ") for string in reviews['user_id']]
reviews['business_id'] = [string.strip(" ") for string in reviews['business_id']]
users['user_id'] = [string.strip(" ") for string in users['user_id']]
business['business_id'] = [string.strip(" ") for string in business['business_id']]

# JOIN
reviews_join = reviews.copy()
reviews_join= reviews_join.rename(columns={'cool':'cool_review', 'funny':'funny_review', 
  'useful':'useful_review'})
reviews_join = reviews_join.merge(users, how='left', left_on='user_id', right_on='user_id')

print("Number of NA users in all business reviews: {}".format(len(reviews_join[pd.isna(
  reviews_join['count_friends'])])))
print('Totals rows in all business reviews: {}'.format(len(reviews_join)))

# Keep only relevant columns for now
reviews_join_user = reviews_join.loc[:,['business_id', 'cool_review', 'funny_review',
       'stars', 'useful_review', 'average_stars', 'cool', 'elite_binary', 'fans',
       'funny', 'review_count', 'useful', 'count_friends', 'reviews_per_month', 
       'fan_outlier', 'friend_outlier']]

# Subset to just food businesses
unique_food_business = set(business['business_id'])

# Subset reviews to just food
reviews_join_user_food = reviews_join_user[reviews_join_user['business_id'].isin(
  unique_food_business)]

print("Number of NA users in all business reviews: {}".format(len(reviews_join_user_food[pd.isna(reviews_join_user_food['count_friends'])])))
print('Totals rows in all business reviews: {}'.format(len(reviews_join_user_food)))

# Correct column dtypes
reviews_join_user_food['cool_review'] = reviews_join_user_food['cool_review'].astype(int)

# Aggregate to business level
reviews_join_user_food = reviews_join_user_food.groupby('business_id').agg(
  {'cool_review':np.mean, 'funny_review':np.mean,
    'stars':np.mean, 'useful_review':np.mean, 
    'average_stars':np.mean, 'cool':np.mean, 'elite_binary':sum,
    'fans':[sum, np.mean],
    'funny':np.mean, 'review_count':[sum, np.mean],
    'useful':[sum, np.mean], 'count_friends':[sum, np.mean],
    'reviews_per_month':np.mean, 'fan_outlier':sum,
    'friend_outlier':sum})

print("Number of NAs in output: {}".format(np.count_nonzero(np.isnan(
  reviews_join_user_food['average_stars']['mean'].values))))
print("Number of Total in output: {}".format(len(reviews_join_user_food)))

# Ensure sums are NA where the mean values are NA (aka fake zeros)
reviews_join_user_food['elite_binary']['sum'] = np.where(pd.isna(
  reviews_join_user_food['average_stars']['mean']), 
  np.nan, 
  reviews_join_user_food['elite_binary']['sum'])
reviews_join_user_food['fans']['sum'] = np.where(pd.isna(
  reviews_join_user_food['average_stars']['mean']), 
  np.nan, 
  reviews_join_user_food['fans']['sum'])
reviews_join_user_food['review_count']['sum'] = np.where(
  pd.isna(reviews_join_user_food['average_stars']['mean']), 
  np.nan, 
  reviews_join_user_food['review_count']['sum'])
reviews_join_user_food['useful']['sum'] = np.where(
  pd.isna(reviews_join_user_food['average_stars']['mean']), 
  np.nan, 
  reviews_join_user_food['useful']['sum'])
reviews_join_user_food['count_friends']['sum'] = np.where(
  pd.isna(reviews_join_user_food['average_stars']['mean']), 
  np.nan, 
  reviews_join_user_food['count_friends']['sum'])
reviews_join_user_food['fan_outlier']['sum'] = np.where(
  pd.isna(reviews_join_user_food['average_stars']['mean']), 
  np.nan, 
  reviews_join_user_food['fan_outlier']['sum'])
reviews_join_user_food['friend_outlier']['sum'] = np.where(
  pd.isna(reviews_join_user_food['average_stars']['mean']), 
  np.nan, 
  reviews_join_user_food['friend_outlier']['sum'])

# Reindex multiindex columns
new_flat_cols = ['_'.join(col).strip() for col in reviews_join_user_food.columns.values]
reviews_join_user_food.columns = new_flat_cols
reviews_join_user_food.reset_index(inplace=True)

reviews_join_user_food.to_csv('data/vegas_business_user_info.csv', index=False)
```

#### 1.2.3 - Clean Business Tables and EDA

Python code to clean and process business attributes

```{r, eval=FALSE}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
from collections import Counter
pd.set_option('display.max_rows', 500)
import json


bus= pd.read_csv('business.csv')

#Get city
my_city = bus[bus['city']=='Las Vegas']
my_city = my_city[my_city['is_open']==1]

# Initial category counts
# Loop through all categories, and count each unique one
All_categories = my_city['categories'].values
All_categories_list = []
for i in All_categories:
    try:
        curr = i.split(',')
        for j in curr:
            All_categories_list.append(j.strip(" "))
    except:
        continue

All_categories_count = Counter(All_categories_list)
categories_df = pd.DataFrame.from_dict(All_categories_count, orient='index')
categories_df.sort_values(0,ascending=False,inplace=True)
categories_df.rename(columns={0:'Count'},inplace=True)


# Extract food related category list, adding on Bars as additional
food_cat_list=['American (New)','American (Traditional)','Canadian (New)','Absinthe Bars ','Beach Bars ','Beer Bar ','Champagne Bars ','Cocktail Bars ','Dive Bars ','Drive-Thru Bars ',
           'Hookah Bars ','Hotel bar ','Irish Pub ','Pubs ','Pulquerias ','Sake Bars ','Speakeasies ','Sports Bars ','Tabac ','Tiki Bars ',
           'Vermouth Bars ','Whiskey Bars ','Wine Bars ','Beer Gardens ','Club Crawl ','Coffeeshops ','Afghan ','African ','Senegalese ',
           'South African ','American ','American ','Andalusian ','Arabian ','Arab Pizza ','Argentine ','Armenian ','Asian Fusion ','Asturian ',
           'Australian ','Austrian ','Baguettes ','Bangladeshi ','Barbeque ','Basque ','Bavarian ','Beer Garden ','Beer Hall ','Beisl ','Belgian ',
           'Flemish ','Bistros ','Black Sea ','Brasseries ','Brazilian ','Brazilian Empanadas ','Central Brazilian ','Northeastern Brazilian ',
           'Northern Brazilian ','Rodizios ','Breakfast & Brunch ','Pancakes ','British ','Buffets ','Bulgarian ','Burgers ','Burmese ','Cafes ',
           'Themed Cafes ','Cafeteria ','Cajun/Creole ','Cambodian ','Canadian ','Canteen ','Caribbean ','Dominican ','Haitian ','Puerto Rican ',
           'Trinidadian ','Catalan ','Cheesesteaks ','Chicken Shop ','Chicken Wings ','Chilean ','Chinese ','Cantonese ','Congee ','Dim Sum ',
           'Fuzhou ','Hainan ','Hakka ','Henghwa ','Hokkien ','Hunan ','Pekinese ','Shanghainese ','Szechuan ','Teochew ','Comfort Food ',
           'Corsican ','Creperies ','Cuban ','Curry Sausage ','Cypriot ','Czech ','Czech/Slovakian ','Danish ','Delis ','Diners ',
           'Dinner Theater ','Dumplings ','Eastern European ','Eritrean ','Ethiopian ','Fast Food ','Filipino ','Fischbroetchen ','Fish & Chips ',
           'Flatbread ','Fondue ','Food Court ','Freiduria ','French ','Alsatian ','Auvergnat ','Berrichon ','Bourguignon ',
           'Mauritius ','Nicoise ','Provencal ','Reunion ','French Southwest ','Galician ','Game Meat ','Gastropubs ','Georgian ','German ',
           'Baden ','Eastern German ','Franconian ','Hessian ','Northern German ','Palatine ','Rhinelandian ','Giblets ','Gluten-Free ','Greek ',
           'Guamanian ','Halal ','Hawaiian ','Heuriger ','Himalayan/Nepalese ','Honduran ','Hong Kong Style Cafe ','Hot Dogs ','Hot Pot ',
           'Hungarian ','Iberian ','Indian ','Indonesian ','International ','Irish ','Island Pub ','Israeli ','Italian ','Abruzzese ',
           'Altoatesine ','Apulian ','Calabrian ','Cucina campana ','Emilian ','Friulan ','Ligurian ','Lumbard ','Napoletana ','Piemonte ',
           'Roman ','Sardinian ','Sicilian ','Tuscan ','Venetian ','Japanese ','Blowfish ','Conveyor Belt Sushi ','Donburi ','Gyudon ',
           'Oyakodon ','Hand Rolls ','Horumon ','Izakaya ','Japanese Curry ','Kaiseki ','Kushikatsu ','Oden ','Okinawan ','Okonomiyaki ',
           'Onigiri ','Ramen ','Robatayaki ','Soba ','Sukiyaki ','Takoyaki ','Tempura ','Teppanyaki ','Tonkatsu ','Udon ','Unagi ',
           'Western Style Japanese Food ','Yakiniku ','Yakitori ','Jewish ','Kebab ','Kopitiam ','Korean ','Kosher ','Kurdish ','Laos ',
           'Laotian ','Latin American ','Colombian ','Salvadoran ','Venezuelan ','Live/Raw Food ','Lyonnais ','Malaysian ','Mamak ','Nyonya ',
           'Meatballs ','Mediterranean ','Falafel ','Mexican ','Eastern Mexican ','Jaliscan ','Northern Mexican ','Oaxacan ','Pueblan ','Tacos ',
           'Tamales ','Yucatan ','Middle Eastern ','Egyptian ','Lebanese ','Milk Bars ','Modern Australian ','Modern European ','Mongolian ',
           'Moroccan ','New Mexican Cuisine ','New Zealand ','Nicaraguan ','Night Food ','Nikkei ','Noodles ','Norcinerie ','Open Sandwiches ',
           'Oriental ','PF/Comercial ','Pakistani ','Pan Asian ','Parent Cafes ','Parma ','Persian/Iranian ','Peruvian ','Pita ','Pizza ',
           'Polish ','Pierogis ','Polynesian ','Pop-Up Restaurants ','Portuguese ','Alentejo ','Algarve ','Azores ','Beira ','Fado Houses ',
           'Madeira ','Minho ','Ribatejo ','Tras-os-Montes ','Potatoes ','Poutineries ','Pub Food ','Rice ','Romanian ','Rotisserie Chicken ',
           'Russian ','Salad ','Sandwiches ','Scandinavian ','Schnitzel ','Scottish ','Seafood ','Serbo Croatian ','Signature Cuisine ',
           'Singaporean ','Slovakian ','Somali ','Soul Food ','Soup ','Southern ','Spanish ','Arroceria / Paella ','Sri Lankan ','Steakhouses ',
           'Supper Clubs ','Sushi Bars ','Swabian ','Swedish ','Swiss Food ','Syrian ','Tabernas ','Taiwanese ','Tapas Bars ','Tapas/Small Plates ',
           'Tavola Calda ','Tex-Mex ','Thai ','Traditional Norwegian ','Traditional Swedish ','Trattorie ','Turkish ','Chee Kufta ','Gozleme ',
           'Homemade Food ','Lahmacun ','Ottoman Cuisine ','Turkish Ravioli ','Ukrainian ','Uzbek ','Vegan ','Vegetarian ','Venison ','Vietnamese ',
           'Waffles ','Wok ','Yugoslav ','Acai Bowls ','Backshop ','Bagels ','Bakeries ','Beer','Bento ',
           'Beverage Store ','Breweries ','Brewpubs ','Bubble Tea ','Butcher ','CSA ','Chimney Cakes ','Churros ','Cideries ','Coffee & Tea ',
           'Coffee & Tea Supplies ','Coffee Roasteries ','Cupcakes ','Custom Cakes ','Delicatessen ','Desserts ',
           'Distilleries ','Do-It-Yourself Food ','Donairs ','Donuts ','Empanadas ',
           'Food Delivery Services ','Food Trucks ','Friterie ','Gelato ','Hawker Centre ','Honey ','Ice Cream & Frozen Yogurt ',
           'Imported Food ','Internet Cafes ','Japanese Sweets ','Taiyaki ','Juice Bars & Smoothies ','Kiosk ',
           'Kombucha ','Meaderies ','Milkshake Bars ','Mulled Wine ','Nasi Lemak ','Organic Stores ','Panzerotti ','Parent Cafes ',
           'Patisserie/Cake Shop ','Piadina ','Poke ','Pretzels ','Salumerie ','Shaved Ice ','Shaved Snow ','Smokehouse ',
           'Candy Stores ','Cheese Shops ','Chocolatiers & Shops ','Dagashi ','Dried Fruit ','Frozen Food ','Fruits & Veggies ',
           'Herbs & Spices ','Macarons ','Meat Shops ','Olive Oil ','Pasta Shops ','Popcorn Shops ','Seafood Markets ','Tofu Shops ',
           'Street Vendors ','Sugar Shacks ','Tea Rooms ','Torshi ','Tortillas ','Water Stores ','Wineries ','Wine Tasting Room ','Zapiekanka ']

food_cat_list = [x.strip() for x in food_cat_list]
food_cat_list_plus = food_cat_list.copy()
food_cat_list_plus.append('Bars')

# Number of unique food categories
len(food_cat_list)


#getting rows that contain any of the food categories above for subsetting
count=0
indices = []
for i in np.arange(len(my_city)):
    cat = my_city['categories'].iloc[i]
    try:
        cats=cat.split(',')
        cats = [i.strip() for i in cats]
        if any(word in cats for word in food_cat_list_plus):
            count +=1
            indices.append(i)
            
    except:
        continue

FoodPlaces = my_city.copy(deep=True)
FoodPlaces = FoodPlaces.iloc[indices,:]
print(FoodPlaces.shape)


# Return top category that isn't restaurant/food. if nothing else, return the generic
def get_type(x):
    cats = x.split(',')
    cats = [i.strip() for i in cats]
    for cat in cats:
        if cat in food_cat_list:
            if(cat=='American (Traditional)' or cat=='American (New)'):
                return 'American'
            else:
                return cat
        else:
            continue
    if 'Bars' in cats:
        return 'Bars'


FoodPlaces['TopCategory'] = FoodPlaces['categories'].apply(get_type)

# How many unique top categories are there?
types = set(FoodPlaces['TopCategory'])
len(types)

#Plot top 25 categories
plt.figure(figsize=(50,20))
plt.tight_layout()
sns.set(font_scale=3)
sns.countplot(x='TopCategory',data=FoodPlaces,orient="v",order = FoodPlaces['TopCategory'].value_counts().iloc[:25].index,palette="Blues_d") 
plt.title('Top 25 Categories Food Categories in Las Vegas')
plt.xticks(rotation=90)
plt.show()

#Fixing JSON formatting in attribute column
def fixattrs(x):
    if isinstance(x,str):
        newx = x.replace('}\"','}').replace('\"{','{').replace('\'{','{').replace(" True","\"True\"").replace(" False","\"False\"").replace("\"u\'","\"").replace('\"\"','\"').replace("\'", "\"").replace('\"\"','\"').replace('{}\"','\"{}\"')
        return json.loads(newx)


FoodPlaces['attribute_dict'] = FoodPlaces['attributes'].apply(fixattrs)

#Getting list of attrs and getting counts
attrs = []
for row in FoodPlaces['attribute_dict']:
    if isinstance(row,dict):
        for i in list(row.keys()):
            attrs.append(i)  
            
attr_counts = Counter(attrs)
attr_counts_dict = dict(attr_counts)
counts = list(attr_counts.values())
newList = [x / len(FoodPlaces) for x in counts]


#Plotting top attributes
attrcount_df = pd.DataFrame({'attribute':list(attr_counts_dict.keys()),'percent':newList})
attrcount_df.reset_index(inplace=True)
attrcount_df.sort_values(by='percent',inplace=True,ascending=False)
plt.figure(figsize=(50,20))
sns.barplot(x="attribute", y="percent", data=attrcount_df[0:18],palette="Blues_d") 
plt.title('Top 18 Attributes for Food Categories in Las Vegas')
plt.xticks(rotation=90)
plt.show()

top_attrs = list(attrcount_df.iloc[0:18,1])


# Function cleaning the attributes, extracting only top ones
def clean_attrs(mdict):
    if isinstance(mdict,dict):
        dictcopy = mdict.copy()
        attrs = list(mdict.keys())
        for attr in attrs:
            if attr not in top_attrs:
                del dictcopy[attr]
        return dictcopy
    else:
        return



FoodPlaces['TopAttrs'] = FoodPlaces['attribute_dict'].apply(clean_attrs)



#check that it filtered some out
FoodPlaces[FoodPlaces['TopAttrs']!=FoodPlaces['attribute_dict']].head()



#one hot encoding sub attributes 
attributes = FoodPlaces['TopAttrs'].apply(pd.Series)
parking = attributes['BusinessParking'].apply(pd.Series)
parking.drop(0,axis=1,inplace=True)

Ambience = attributes['Ambience'].apply(pd.Series)
Ambience.drop(0,axis=1,inplace=True)

Ambience = attributes['Ambience'].apply(pd.Series)
Ambience.drop(0,axis=1,inplace=True)

attributes.drop('Ambience',axis=1,inplace=True)
attributes.drop('BusinessParking',axis=1,inplace=True)
attributes.drop('GoodForMeal',axis=1,inplace=True)


HotAttrs = pd.concat([attributes,parking,Ambience,Meal],axis=1)


FinalFood = pd.concat([FoodPlaces,HotAttrs],axis=1)
FinalFood.drop(['Unnamed: 0','attributes','is_open','hours','TopAttrs','attribute_dict','categories'],axis=1,inplace=True)


# investigating nan None problem
list(FinalFood['OutdoorSeating'].unique())

# Fixing missing values
FinalFood['RestaurantsGoodForGroups'].replace('None', None, inplace=True)
FinalFood['BikeParking'].replace('None', None, inplace=True)
FinalFood['RestaurantsPriceRange2'].replace('None', None, inplace=True)
FinalFood['HasTV'].replace('None', None, inplace=True)
FinalFood['RestaurantsGoodForGroups'].replace('None', None, inplace=True)
FinalFood['OutdoorSeating'].replace('None', None, inplace=True)

FinalFood = FinalFood.replace('None', None)

#Verifying it worked
list(FinalFood['WiFi'].unique())

FinalFood.to_csv('vegas_food_businesses_clean.csv')
```


#### 1.2.4 - Join Tables into Final Dataset

Python code to join all the tables together into one clean dataset

```{r, eval=FALSE}
import numpy as np
import pandas as pd

clean_business = pd.read_csv('data/vegas_food_businesses_cleaned.csv')
clean_reviews = pd.read_csv('data/review_checkin_final.csv')
clean_users = pd.read_csv('data/vegas_business_user_info.csv')

clean_business.drop('Unnamed: 0', axis=1, inplace=True) 

# Rename review dataset for clarity
clean_reviews = clean_reviews.rename(columns={'cool_stand':'cool_review_pm', 'funny_stand':'funny_review_pm',
                                              'useful_stand':'useful_review_pm', 'useful':'useful_review_count',
                                              'funny':'funny_review_count', 'cool':'cool_review_count',
                                              'review':'review_count', 'checkin':'checkin_count'})

clean_users = clean_users.rename(columns={'stars_mean':'stars_review_mean', 'average_stars_mean':'stars_users_mean',
                                          'cool_mean':'cool_users_mean', 'elite_binary_sum':'elite_users_sum',
                                          'fans_sum':'fans_users_sum', 'fans_mean':'fans_users_mean',
                                          'funny_mean':'funny_users_mean', 'review_count_sum':'review_users_sum',
                                          'review_count_mean':'review_users_mean', 'useful_sum':'useful_users_sum',
                                          'useful_mean':'useful_users_mean', 'count_friends_sum':'friend_number_count',
                                          'count_friends_mean':'friend_number_mean', 'reviews_per_month_mean':'reviews_users_pm_mean',
                                          'fan_outlier_sum':'fan_outlier_count','friend_outlier_sum':'friend_outlier_count'})

clean_business = clean_business.rename(columns={'review_count':'review_count_business', 
  'stars':'stars_business'})

vegas_yelp_dataset = pd.merge(clean_business, clean_reviews, how='left', left_on='business_id', 
                              right_on='business_id')
vegas_yelp_dataset = pd.merge(vegas_yelp_dataset, clean_users, how='left', left_on='business_id', 
                              right_on='business_id')
vegas_yelp_dataset.to_csv('data/vegas_yelp_dataset.csv')

print('Overall columns:')
print(vegas_yelp_dataset.columns)

```



